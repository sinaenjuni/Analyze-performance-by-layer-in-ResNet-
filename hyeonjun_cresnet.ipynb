{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\y2k43\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\y2k43\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\y2k43\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\y2k43\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\y2k43\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\y2k43\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\y2k43\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\y2k43\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\y2k43\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\y2k43\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\y2k43\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\y2k43\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras import Input\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "#add savemodel \n",
    "import pandas as pd\n",
    "\n",
    "#입력 매개변수 리스트 수정\n",
    "#add fileter number flag\n",
    "#입력 매개변수 리스트 수정 export\n",
    "#0번째 블록의 resblock의 BN과정 삭제\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                 num_filters,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "   \n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=regularizers.l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv1_layer(inputs,\n",
    "                num_filters=64,\n",
    "                kernel_size=7,\n",
    "                strides=2, \n",
    "                activation='relu',\n",
    "                batch_normalization=True, \n",
    "                conv_first=True):\n",
    "    \n",
    "    x = resnet_layer(inputs,\n",
    "                 num_filters=num_filters,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=strides,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True)\n",
    "    \n",
    "    '''\n",
    "    first_conv = Conv2D(64,\n",
    "                  kernel_size=(7, 7),\n",
    "                  strides=(2, 2),\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "  \n",
    "    x = inputs\n",
    "    x = conv1_layer(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "'''\n",
    "    \n",
    "    return x\n",
    "\n",
    "def shortcut_layer(inputs, num_filters, isIdentity, isBatch_normalization, shortcut_strides):\n",
    "    shortcut = inputs\n",
    "    \n",
    "    if isIdentity == True:\n",
    "        shortcut = Conv2D(num_filters, (1, 1), strides=shortcut_strides, padding='valid')(shortcut)\n",
    "    if isBatch_normalization == True:\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "        \n",
    "    return shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(input_shape, re=[4, [2,2,2,2], 2], num_classes=2, isNumFilers=True):\n",
    "    \n",
    "    name = f'{re}'\n",
    "    \n",
    "    num_filters = 64\n",
    "    count = 0\n",
    "    inputs = Input(shape=input_shape) #(224, 224, 3)\n",
    "    print(inputs)\n",
    "    \n",
    "    '''x = resnet_layer(inputs,\n",
    "                 num_filters,\n",
    "                 kernel_size=7,\n",
    "                 strides=2,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True)'''\n",
    "    count+=1\n",
    "    x = conv1_layer(inputs=inputs)\n",
    "    print(x)\n",
    "    \n",
    "    x = MaxPooling2D((3, 3), 2, padding='same')(x) #(56, 56, 3)\n",
    "    print(x)\n",
    "    \n",
    "    #shortcut = x\n",
    "    \n",
    "    for layer in range(re[0]): #4 0~3\n",
    "        print('----------------')\n",
    "        #shortcut = x\n",
    "        for res_block in range(re[1][layer]):  #2 0~1\n",
    "            shortcut = x\n",
    "            \n",
    "            print('----------------')\n",
    "            for in_res_block in range(re[2]): # 2 0~1\n",
    "                \n",
    "                strides = 1\n",
    "                if layer > 0 and res_block == 0 and in_res_block == 0:  # first layer but not first stack\n",
    "                    strides = 2  # downsample\n",
    "                    \n",
    "                isActivation = 'relu'\n",
    "                if in_res_block == re[2]-1:\n",
    "                    isActivation = None\n",
    "                count+=1\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 strides=strides,\n",
    "                                activation=isActivation)\n",
    "                \n",
    "                print(f'{count}::{num_filters}X{num_filters},{strides} : {x}')\n",
    "\n",
    "            '''if layer != 0 and res_block == 0:'''\n",
    "            '''if res_block == 0:\n",
    "                shortcut = Conv2D(num_filters, (1, 1), strides=shortcut_strides, padding='valid')(shortcut)\n",
    "                shortcut = BatchNormalization()(shortcut)'''\n",
    "            \n",
    "            shortcut_strides=1\n",
    "            if layer > 0 and res_block == 0:  # first layer but not first stack\n",
    "                    shortcut_strides = 2  # downsample\n",
    "            \n",
    "            if layer == 0 and res_block == 0:\n",
    "                shortcut = shortcut_layer(shortcut,\n",
    "                                          num_filters,\n",
    "                                          isIdentity=False,\n",
    "                                          isBatch_normalization=False, \n",
    "                                          shortcut_strides=shortcut_strides)\n",
    "                \n",
    "            elif layer > 0 and res_block == 0:\n",
    "                shortcut = shortcut_layer(shortcut, \n",
    "                                          num_filters,\n",
    "                                          isIdentity=True,\n",
    "                                          isBatch_normalization=True,\n",
    "                                          shortcut_strides=shortcut_strides)\n",
    "                \n",
    "            print(shortcut)\n",
    "            x = Add()([x, shortcut])\n",
    "            print(x)\n",
    "            x = Activation('relu')(x)\n",
    "            print(x)\n",
    "            \n",
    "        if isNumFilers == True:\n",
    "            num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    \n",
    "    #x = AveragePooling2D(pool_size=8)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    print(x)\n",
    "    #y = Flatten()(x)\n",
    "    count+=1\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(x)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model, count, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_path(base_dir):\n",
    "    dir_path = os.path.dirname(base_dir)\n",
    "    file_name = os.path.basename(base_dir)\n",
    "    full_path = os.path.join(dir_path, file_name)\n",
    "    \n",
    "    return dir_path, file_name, full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewResult(history, base_dir):\n",
    "    \n",
    "    '''image_dir = os.path.dirname(base_dir)\n",
    "    image_file = os.path.basename(base_dir) + '_image.png'\n",
    "    full_path = os.path.join(image_dir, image_file)'''\n",
    "    \n",
    "    #model_base_dir = f'/data/hyeon_model_save/layer_image/{classes}'\n",
    "    \n",
    "    dir_path, file_name, full_path = make_path(base_dir+'_image.png')\n",
    "    try:\n",
    "        os.makedirs(dir_path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(dir_path):\n",
    "            raise\n",
    "\n",
    "\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    #epochs = range(1, len(acc) + 1)\n",
    "    epochs = [tick for tick in range(1, len(acc)+1)]\n",
    "\n",
    "    fig = plt.figure(figsize=(10,4))\n",
    "    plt.suptitle(f'{file_name}')\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    \n",
    "    plt.plot(epochs, acc, 'b', label='Training acc', linestyle=':')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation acc', linestyle='-')\n",
    "\n",
    "    \n",
    "    plt.xticks = np.arange(min(acc), max(acc)+1, 0.1, dtype='f')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(b=True, which='both', axis='both', linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss', linestyle=':')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss', linestyle=\"-\")\n",
    "    plt.title(f'Loss')\n",
    "    plt.grid(b=True, which='both', axis='both', linestyle='--', linewidth=0.5)\n",
    "    plt.legend()\n",
    "    plt.yticks = np.arange(min(acc), max(acc)+1, 0.1, dtype='f')\n",
    "    #fig.savefig(full_path)\n",
    "    print(full_path)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewResult_v2(history, base_dir):\n",
    "\n",
    "    dir_path, file_name, full_path = make_path(base_dir+'_image.png')\n",
    "    try:\n",
    "        os.makedirs(dir_path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(dir_path):\n",
    "            raise\n",
    "            \n",
    "\n",
    " \n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    '''acc = history['acc']\n",
    "    val_acc = history['val_acc']\n",
    "    loss = history['loss']\n",
    "    val_loss = history['val_loss']'''\n",
    "    \n",
    "    #epochs = range(1, len(acc) + 1)\n",
    "    epochs = [tick for tick in range(1, len(acc)+1)]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,4))\n",
    "    plt.suptitle(f'{file_name}')\n",
    "    \n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.set(title='Accuracy', xlabel='epoch', ylabel='accuracy')\n",
    "    ax1.plot(epochs, acc, 'b', label='Training acc', linestyle=':')\n",
    "    ax1.plot(epochs, val_acc, 'r', label='Validation acc', linestyle='-')\n",
    "    ax1.grid(b=True, which='both', axis='both', linestyle='--', linewidth=0.5)\n",
    "    ax1.legend()\n",
    "    start, end = ax1.get_ylim()\n",
    "    ax1.yaxis.set_ticks(np.arange(start, end, 0.05))\n",
    "    ax1.yaxis.set_major_formatter(plticker.FormatStrFormatter('%0.2f'))\n",
    "    ax1.xaxis.set_major_formatter(plticker.FormatStrFormatter('%0.1f'))\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.set(title='Loss', xlabel='epoch', ylabel='loss')\n",
    "    ax2.plot(epochs, loss, 'b', label='Training loss', linestyle=':')\n",
    "    ax2.plot(epochs, val_loss, 'r', label='Validation loss', linestyle=\"-\")\n",
    "    ax2.grid(b=True, which='both', axis='both', linestyle='--', linewidth=0.5)\n",
    "    ax2.legend()\n",
    "    start, end = ax2.get_ylim()\n",
    "    ax2.yaxis.set_ticks(np.arange(start, end, 0.5))\n",
    "    ax2.yaxis.set_major_formatter(plticker.FormatStrFormatter('%0.1f'))\n",
    "    ax2.xaxis.set_major_formatter(plticker.FormatStrFormatter('%0.1f'))\n",
    "    fig.savefig(full_path)\n",
    "    print(full_path)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result_image_list(model_list, history_list, base_dir):\n",
    "    for index in range(len(history_list)):\n",
    "        viewResult_v2(history_list[index],\n",
    "                      base_dir+f\"result_image/{model_list[index][1]}_{model_list[index][2]}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, base_dir):         \n",
    "    dir_path, file_name, full_path = make_path(base_dir)\n",
    "    try:\n",
    "        os.makedirs(dir_path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(dir_path):\n",
    "            raise\n",
    "\n",
    "    model_json = model.to_json()\n",
    "    with open(full_path, \"w\") as json_file: \n",
    "        json_file.write(model_json)\n",
    "    print(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_list(model_list, base_dir):\n",
    "    for model in model_list:\n",
    "        save_model(model[0], base_dir+f\"model/{model[1]}_{model[2]}_model.json\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weight(model, base_dir):\n",
    "    dir_path, file_name, full_path = make_path(base_dir)\n",
    "    try:\n",
    "        os.makedirs(dir_path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(dir_path):\n",
    "            raise\n",
    "            \n",
    "    model.save_weights(full_path)\n",
    "    print(full_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weight_list(model_list, base_dir):\n",
    "    for model in model_list:\n",
    "        save_weight(model[0], base_dir+f\"weight/{model[1]}_{model[2]}_weight.h5\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history(model_list, history_list, base_dir):\n",
    "    dir_path, file_name, full_path = make_path(base_dir+'history/_history.txt')\n",
    "    try:\n",
    "        os.makedirs(dir_path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(dir_path):\n",
    "            raise\n",
    "\n",
    "    with open(full_path, 'w') as f:\n",
    "        for index in range(len(history_list)):\n",
    "            f.write(f\"{model_list[index][1]}_{model_list[index][2]}\\n\")\n",
    "            f.write(f\"acc\\n{history_list[index].history['acc']}\\n\")\n",
    "            f.write(f\"loss\\n{history_list[index].history['loss']}\\n\")\n",
    "            f.write(f\"val_acc\\n{history_list[index].history['val_acc']}\\n\")          \n",
    "            f.write(f\"val_loss\\n{history_list[index].history['val_loss']}\\n\") \n",
    "        print(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model_list, test_generator, base_dir):\n",
    "    dir_path, file_name, full_path = make_path(base_dir+'_evaluate.txt')\n",
    "    try:\n",
    "        os.makedirs(dir_path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(dir_path):\n",
    "            raise\n",
    "    \n",
    "    with open(full_path, 'w') as fh:\n",
    "        for model in model_list:\n",
    "            scores = model[0].evaluate_generator(test_generator, steps=test_generator.n/test_generator.batch_size)\n",
    "            fh.write(\"[%s_%s] \\t %.2f%%\" %(model[1], model[2], scores[1]*100))\n",
    "            print(\"[%s_%s] \\t %.2f%%\" %(model[1], model[2], scores[1]*100))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_summary(model, base_dir):\n",
    "    dir_path, file_name, full_path = make_path(base_dir)\n",
    "    try:\n",
    "        os.makedirs(dir_path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(dir_path):\n",
    "            raise\n",
    "    \n",
    "    with open(full_path, 'w') as fh:\n",
    "        # Pass the file handle in as a lambda function to make it callable\n",
    "        model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "    print(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_summary_list(model_list, base_dir):\n",
    "    for model in model_list:\n",
    "        save_model_summary(model[0], base_dir+f\"summary/{model[1]}_{model[2]}_summary.txt\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
